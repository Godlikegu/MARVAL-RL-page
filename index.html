<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>MARVAL: Masked Auto-Regressive Variational Acceleration - CVPR 2026</title>
  <meta name="description" content="Project page for MARVAL, accepted to CVPR 2026." />
  <link rel="stylesheet" href="style.css" />
  <link rel="preconnect" href="https://fonts.googleapis.com" />
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@300;400;600;700&display=swap" rel="stylesheet" />
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
</head>
<body>
  <div class="container">
    <header class="header">
      <h1 class="title">Masked Auto-Regressive Variational Acceleration</h1>
      <h2 class="conference">CVPR 2026</h2>
      
      <div class="authors">
        <span class="author">Yuxuan Gu<sup>1</sup></span>, 
        <span class="author">Weimin Bai<sup>1</sup></span>, 
        <span class="author">Yifei Wang<sup>1</sup></span>, 
        <span class="author">Weijian Luo<sup>1</sup></span>, 
        <span class="author">He Sun<sup>1</sup></span>
      </div>
      
      <div class="affiliations">
        <span class="affiliation"><sup>1</sup>Peking University</span>
      </div>

      <div class="links">
        <a href="https://arxiv.org/pdf/2511.15190.pdf" class="btn" target="_blank"><i class="fas fa-file-pdf"></i> Paper</a>
        <a href="https://arxiv.org/abs/2511.15190" class="btn" target="_blank"><i class="fas fa-book"></i> arXiv</a>
        <a href="#" class="btn btn-disabled"><i class="fab fa-github"></i> Code (Soon)</a>
      </div>
    </header>

    <section class="teaser">
      <div class="teaser-placeholder">
        <p>Replace this box with your teaser image: <code>&lt;img src="assets/teaser.pdf" alt="MARVAL Teaser"&gt;</code></p>
      </div>
      <p class="caption">
        <strong>Figure 1:</strong> MARVAL distills masked auto-regressive diffusion into a single-step generator, enabling fast sampling and practical RL with preference-aligned rewards.
      </p>
    </section>

    <section class="abstract">
      <h2>Abstract</h2>
      <p>
        Masked auto-regressive diffusion models (MAR) combine the expressive power of diffusion models with the flexibility of masked auto-regressive generation, but suffer from slow inference due to a nested outer unmasking loop and inner diffusion chain. We propose <strong>MARVAL</strong> (Masked Auto-Regressive Variational Acceleration), a distillation-based framework that compresses the diffusion process into a single auto-regressive step while preserving flexible unmasking orders. 
      </p>
      <p>
        This not only achieves substantial inference acceleration but also enables practical reinforcement learning post-training with verifiable rewards, yielding scalable, human-preferred, and fast generative models.
      </p>
    </section>

    <section class="method">
      <h2>Method Overview</h2>
      <p>
        MARVAL targets the fundamental efficiency bottleneck of masked auto-regressive diffusion models: a hierarchical inference scheme that combines an outer masking schedule with an inner, multi-step diffusion chain. 
      </p>
      <p>
        By introducing a score-based variational distillation objective, MARVAL compresses the diffusion denoising process into a single generation step. Instead of running a full diffusion chain at each unmasking step, MARVAL directly predicts high-quality samples in one shot.
      </p>
      <div class="highlights">
        <ul>
          <li><strong>Novel Objective:</strong> A score-based variational objective to distill MAR models into single-step generators.</li>
          <li><strong>MARVAL-RL:</strong> An efficient RL framework enabling post-training with verifiable rewards.</li>
          <li><strong>Performance:</strong> Extensive experiments on ImageNet 256×256 demonstrating strong sample quality, significant acceleration, and consistent gains in CLIP and image-reward scores.</li>
        </ul>
      </div>
    </section>

    <section class="results">
      <h2>Results</h2>
      <div class="metrics-grid">
        <div class="metric-box">
          <h3>FID 2.00</h3>
          <p>ImageNet 256×256</p>
        </div>
        <div class="metric-box">
          <h3>30×+</h3>
          <p>Sampling Speedup</p>
        </div>
        <div class="metric-box">
          <h3>↑ CLIP / Reward</h3>
          <p>MARVAL-RL Gains</p>
        </div>
      </div>
    </section>

    <section class="citation">
      <h2>Citation</h2>
      <pre><code>@inproceedings{gu2026marval,
  title     = {Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning},
  author    = {Gu, Yuxuan and Bai, Weimin and Wang, Yifei and Luo, Weijian and Sun, He},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2026}
}</code></pre>
    </section>
  </div>

  <footer class="footer">
    <p>© <span id="year"></span> Yuxuan Gu. Hosted on GitHub Pages.</p>
  </footer>

  <script src="script.js"></script>
</body>
</html>