<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>MARVAL: Masked Auto-Regressive Variational Acceleration - CVPR 2026</title>
    <meta
      name="description"
      content="Project page for MARVAL (Masked Auto-Regressive Variational Acceleration): fast inference for masked auto-regressive diffusion models that enables practical reinforcement learning, accepted to CVPR 2026."
    />
    <link rel="stylesheet" href="style.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <header class="hero">
      <div class="hero-inner">
        <div class="hero-text">
          <p class="badge">CVPR 2026 · Generative Modeling & RL</p>
          <h1 id="paper-title">Masked Auto-Regressive Variational Acceleration</h1>
          <p class="authors" id="paper-authors">
            Yuxuan Gu · Weimin Bai · Yifei Wang · Weijian Luo · He Sun
          </p>
          <p class="venue" id="paper-venue">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) · 2026</p>
          <div class="hero-actions">
            <a
              id="btn-paper"
              class="btn primary"
              href="https://arxiv.org/pdf/2511.15190.pdf"
              target="_blank"
              rel="noopener"
              >Read Paper (PDF)</a
            >
            <a
              id="btn-code"
              class="btn ghost"
              href="#"
              target="_blank"
              rel="noopener"
              >Code (coming soon)</a
            >
            <a
              id="btn-arxiv"
              class="btn ghost"
              href="https://arxiv.org/abs/2511.15190"
              target="_blank"
              rel="noopener"
              >arXiv</a
            >
          </div>
          <p class="hero-abstract" id="paper-abstract">
            MARVAL (Masked Auto-Regressive Variational Acceleration) compresses the diffusion denoising chain in
            masked auto-regressive models into a single fast generation step, while preserving flexible unmasking
            orders. This enables more than 30× faster sampling and, crucially, practical reinforcement learning
            post-training with verifiable rewards for large-scale generative models.
          </p>
        </div>
        <div class="hero-visual">
          <div class="preview-card">
            <div class="preview-image">
              <!-- Teaser figure: copy your teaser.pdf into assets/teaser.pdf -->
              <embed
                src="assets/teaser.pdf"
                type="application/pdf"
                style="width: 100%; height: 100%; border: none;"
              />
            </div>
            <p class="preview-caption">
              Figure 1: MARVAL distills masked auto-regressive diffusion into a single-step generator, enabling fast
              sampling and practical RL with preference-aligned rewards.
            </p>
          </div>
        </div>
      </div>
    </header>

    <main class="content">
      <section id="abstract" class="section">
        <h2>Abstract</h2>
        <p>
          Masked auto-regressive diffusion models (MAR) combine the expressive power of diffusion models with the
          flexibility of masked auto-regressive generation, but suffer from slow inference due to a nested outer
          unmasking loop and inner diffusion chain. We propose MARVAL (Masked Auto-Regressive Variational Acceleration),
          a distillation-based framework that compresses the diffusion process into a single auto-regressive step while
          preserving flexible unmasking orders. This not only achieves substantial inference acceleration but also
          enables practical reinforcement learning post-training with verifiable rewards, yielding scalable,
          human-preferred, and fast generative models.
        </p>
        <p>
          我们提出的 MARVAL 框架，在保持 masked auto-regressive 模型表达能力与灵活解码顺序的前提下，通过新的变分目标将扩散链路蒸馏为一步生成，大幅提升采样速度（超过 30×），并让带可验证奖励的强化学习后训练真正可行，从而在大规模生成任务中实现既高效又符合人类偏好的模型。
        </p>
      </section>

      <section id="overview" class="section">
        <h2>Method Overview</h2>
        <p>
          MARVAL targets the fundamental efficiency bottleneck of masked auto-regressive diffusion models: a hierarchical
          inference scheme that combines an outer masking schedule with an inner, multi-step diffusion chain. This
          structure provides strong modeling power but leads to slow sampling and makes reinforcement learning with
          explicit rewards prohibitively expensive for practical deployment.
        </p>
        <div class="grid two-cols">
          <div class="card">
            <h3>Key Idea</h3>
            <p>
              MARVAL introduces a score-based variational distillation objective that compresses the diffusion denoising
              process of masked auto-regressive models into a single generation step, while retaining the flexible
              unmasking order. Instead of running a full diffusion chain at each unmasking step, MARVAL directly
              predicts high-quality samples in one shot, achieving substantial speedups without sacrificing sample
              quality.
            </p>
          </div>
          <div class="card">
            <h3>Contributions</h3>
            <ul>
              <li>
                A novel score-based variational objective to distill masked auto-regressive diffusion models into a
                single-step generator, while preserving flexible unmasking.
              </li>
              <li>
                MARVAL-RL: an efficient reinforcement learning framework for masked auto-regressive models that enables
                practical RL post-training with verifiable rewards.
              </li>
              <li>
                Extensive experiments on ImageNet 256×256 demonstrating strong sample quality and significant acceleration,
                together with consistent gains in CLIP and image-reward scores on entity-centric benchmarks.
              </li>
            </ul>
          </div>
        </div>
      </section>

      <section id="results" class="section">
        <h2>Results</h2>
        <p>
          MARVAL delivers both state-of-the-art image generation quality and dramatic speed improvements over
          masked auto-regressive diffusion baselines. It also makes reinforcement learning with preference-based rewards
          computationally feasible at scale.
        </p>
        <div class="grid three-cols">
          <div class="card metric-card">
            <p class="metric-label">ImageNet 256×256</p>
            <p class="metric-value">FID 2.00</p>
            <p class="metric-desc">High-fidelity samples with MARVAL-Huge</p>
          </div>
          <div class="card metric-card">
            <p class="metric-label">Sampling Speed</p>
            <p class="metric-value">30×+</p>
            <p class="metric-desc">Speedup over MAR-diffusion baselines</p>
          </div>
          <div class="card metric-card">
            <p class="metric-label">MARVAL-RL</p>
            <p class="metric-value">↑ CLIP / Reward</p>
            <p class="metric-desc">Consistent gains in preference-aligned metrics</p>
          </div>
        </div>
      </section>

      <section id="resources" class="section">
        <h2>Resources</h2>
        <div class="grid two-cols">
          <div class="card">
            <h3>Code</h3>
            <p>
              Code and instructions to reproduce MARVAL and MARVAL-RL will be released soon. Stay tuned for an official
              implementation and training scripts.
            </p>
            <a id="link-code" href="#" target="_blank" rel="noopener" class="text-link">GitHub Repository (coming soon) →</a>
          </div>
          <div class="card">
            <h3>Data / Models</h3>
            <p>
              Optionally provide links to datasets, pretrained models, or demo videos.
            </p>
            <ul class="resource-list">
              <li><a href="#" target="_blank" rel="noopener">Dataset download (optional)</a></li>
              <li><a href="#" target="_blank" rel="noopener">Pretrained model (optional)</a></li>
              <li><a href="#" target="_blank" rel="noopener">Demo video (optional)</a></li>
            </ul>
          </div>
        </div>
      </section>

      <section id="bibtex" class="section">
        <h2>Citation</h2>
        <p>If you find this work useful, please cite:</p>
        <pre class="bibtex">
@inproceedings{gu2026marval,
  title     = {Masked Auto-Regressive Variational Acceleration: Fast Inference Makes Practical Reinforcement Learning},
  author    = {Gu, Yuxuan and Bai, Weimin and Wang, Yifei and Luo, Weijian and Sun, He},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2026}
}
        </pre>
      </section>

      <section id="contact" class="section">
        <h2>Contact</h2>
        <p>
          For questions, please contact
          <a href="mailto:your.email@example.com">your.email@example.com</a>. You can replace this address with your
          own preferred contact email.
        </p>
      </section>
    </main>

    <footer class="site-footer">
      <p>
        © <span id="year"></span> MARVAL Authors. Built with ❤️ and hosted on
        <a href="https://pages.github.com/" target="_blank" rel="noopener">GitHub Pages</a>.
      </p>
    </footer>

    <script src="script.js"></script>
  </body>
</html>

